{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e166175",
   "metadata": {},
   "source": [
    "# Stable Diffusion Inference using HuggingFace\n",
    "\n",
    "This notebook aims to show you how to run a Stable Diffusion model using the `diffusers` library from HuggingFace.\n",
    "\n",
    "More information in: https://huggingface.co/docs/diffusers/en/quicktour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4282fbeb",
   "metadata": {},
   "source": [
    "### Check that the GPU is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5085e0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65756de",
   "metadata": {},
   "source": [
    "## Install Diffusers library\n",
    "\n",
    "Here is the command to install diffusers, transformers, torch and accelerate libs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23d18ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade diffusers transformers torch accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18111cb7",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bb9763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af65c2d7",
   "metadata": {},
   "source": [
    "## Create an output folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7422e8af",
   "metadata": {},
   "source": [
    "Check if output directory exists. If folder doesn't exist, then create it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c5e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = 'lab_1_generated_outputs/'\n",
    "\n",
    "if not os.path.isdir(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259e4196",
   "metadata": {},
   "source": [
    "## Select model and parameters\n",
    "\n",
    "Stable Diffusion models in HuggingFace:\n",
    "- https://huggingface.co/CompVis/stable-diffusion-v1-4\n",
    "- https://huggingface.co/runwayml/stable-diffusion-v1-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df93bc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters ----------------------------------------\n",
    "MODEL_ID = \"runwayml/stable-diffusion-v1-5\"\n",
    "# MODEL_ID = \"CompVis/stable-diffusion-v1-4\"\n",
    "\n",
    "# GPU parameters  ----------------------------------------\n",
    "DEVICE = \"cuda\"  # Use cuda to run on GPU\n",
    "\n",
    "# Scheduler parameters ----------------------------------------\n",
    "SCHEDULER = \"EULER_ANCESTRAL\"  # Choose from [\"EULER_ANCESTRAL\", \"EULER\", \"DDIMS\", \"K-LMS\", \"PNDM\"]\n",
    "BETA_END = 0.012\n",
    "BETA_SCHEDULE = \"scaled_linear\"\n",
    "BETA_START = 0.00085\n",
    "NUM_TRAIN_STEPS = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d64a85f",
   "metadata": {},
   "source": [
    "## Pipeline creation with a specific scheduler\n",
    "\n",
    "If you have small GPU (less than 10GB) then you must use `float16` precision instead of `float32`.\n",
    "\n",
    "More info about schedulers: https://github.com/huggingface/diffusers/tree/main/src/diffusers/schedulers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e493b9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import (\n",
    "    StableDiffusionPipeline,\n",
    "    DDIMScheduler,\n",
    "    LMSDiscreteScheduler,\n",
    "    PNDMScheduler,\n",
    "    EulerDiscreteScheduler,\n",
    "    EulerAncestralDiscreteScheduler,\n",
    ")\n",
    "\n",
    "def create_pipeline(model_path):\n",
    "\n",
    "    SCHEDULER_MAP = {\n",
    "        \"DDIMS\": DDIMScheduler,\n",
    "        \"EULER_ANCESTRAL\": EulerAncestralDiscreteScheduler,\n",
    "        \"EULER\": EulerDiscreteScheduler,\n",
    "        \"K-LMS\": LMSDiscreteScheduler,\n",
    "        \"PNDM\": PNDMScheduler,\n",
    "    }\n",
    "\n",
    "    scheduler = SCHEDULER_MAP[SCHEDULER](\n",
    "        beta_start=BETA_START,\n",
    "        beta_end=BETA_END,\n",
    "        beta_schedule=BETA_SCHEDULE,\n",
    "        # num_train_timesteps=NUM_TRAIN_STEPS,\n",
    "    )\n",
    "\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        model_path,\n",
    "        scheduler=scheduler,\n",
    "        torch_dtype=torch.float16,\n",
    "        revision=\"fp16\",\n",
    "        # safety_checker=None,\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eadc19",
   "metadata": {},
   "source": [
    "The `safety_checker` parameter is to filter out unsafe content from generated images. If enabled it returns a completely black image when the generated image violates certain rules, the \"NSFW\" (not safe for work) concept embeddings generated from CLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e975cd5",
   "metadata": {},
   "source": [
    "### Create a new pipeline. This can take a few minutes... be patient :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d9404f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe = create_pipeline(model_path=MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004d0c20",
   "metadata": {},
   "source": [
    "## Let's play!! Generate one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336ac174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the prompt or instructions for generating the image\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "\n",
    "# Generate the image\n",
    "image = pipe(prompt, guidance_scale=7.5, num_inference_steps=50, height=512, width=512).images[0]\n",
    "\n",
    "# Save the image\n",
    "image.save(f\"{OUTPUT_DIR}/astronaut_rides_horse.png\")\n",
    "\n",
    "# Show the image\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce128179",
   "metadata": {},
   "source": [
    "## Using SEED\n",
    "You will have seen that if you run the previous cell it generates a completely new image and overwrites the one you had already saved! :(\n",
    "To avoid this, it is best to set a seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16391a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFERENCE_SEED = 1122334455\n",
    "\n",
    "# Set seed\n",
    "custom_generator = torch.Generator(device='cuda').manual_seed(INFERENCE_SEED)\n",
    "\n",
    "# And then add \"generator=custom_generator\" as pipe() inference parameter\n",
    "image = pipe(prompt, generator=custom_generator, guidance_scale=7.5, num_inference_steps=20, height=512, width=512).images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402f7386",
   "metadata": {},
   "source": [
    "Now we see that it always generates the same image even if you repeat the execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d04fd6c",
   "metadata": {},
   "source": [
    "## Generator method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f7afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(pipe, prompt, steps=80, h=512, w=512, guidance_scale=7, strength=0.75, seed=custom_generator, save_image=True): \n",
    "    print(prompt)\n",
    "    image = pipe(prompt, num_inference_steps=steps, height=h, width=w, guidance_scale=guidance_scale, strength=strength, generator=seed)[\"images\"][0]\n",
    "    display(image)\n",
    "    if save_image == True:\n",
    "        outfilename = f'{OUTPUT_DIR}/{INFERENCE_SEED}_1_' + prompt.replace(' ', '_') + '.png'\n",
    "        image.save(outfilename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f138cce9",
   "metadata": {},
   "source": [
    "## Generate image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f320df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "generate_image(pipe, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b930556",
   "metadata": {},
   "source": [
    "### Image Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0be9b1",
   "metadata": {},
   "source": [
    "In my machine there is a big GPU that can generate images larger than 2048x2048... but a memory error occurs if you try to run it in smaller GPUs.\n",
    "\n",
    "`Experiment`: try to find the limit of your GPU. But... as you can see, the model does not generate the images properly if you ask it to generate at a larger size than the one it is trained to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a21d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "generate_image(pipe, prompt, h=128, w=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bea6262",
   "metadata": {},
   "source": [
    "### Prompt Enginering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc0db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a female warrior\"\n",
    "generate_image(pipe, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5279e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a portrait of a female warrior, by greg rutkowski, highly detailed, HQ, symmetrical, trending on artstation, digital painting, artstation, concept art, smooth, sharp focus, illustration, cinematic lighting\"\n",
    "generate_image(pipe, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aea9832",
   "metadata": {},
   "source": [
    "### Negative Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aadd9c",
   "metadata": {},
   "source": [
    "`Experiment (optional)` : Search for information on `negative prompts` and how to use it with HuggingFace diffusers library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cad488c",
   "metadata": {},
   "source": [
    "### Guidance Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef9e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"overgrown foliage taking over an abandoned robot body, close - up, biopunk, bokeh, beautiful, lens flare, emotional, sweet, flowers, detailed, picture, trending on artstation, award - winning, shiny, golden\"\n",
    "generate_image(pipe, prompt, steps=200, guidance_scale=1, strength=0.9, h=512, w=768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb1a9ca",
   "metadata": {},
   "source": [
    "FYI: `\"guidance_scale\"` is a parameters related to how close the image should be to the prompt. However, high values may not work correctly, depending on each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae8e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"overgrown foliage taking over an abandoned robot body, close - up, biopunk, bokeh, beautiful, lens flare, emotional, sweet, flowers, detailed, picture, trending on artstation, award - winning, shiny, golden\"\n",
    "generate_image(pipe, prompt, steps=200, guidance_scale=20, strength=0.9, h=512, w=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db10106",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a portrait of Elon Musk as superman, realistic portrait, symmetrical, highly detailed, digital painting, artstation, concept art, smooth, sharp focus, illustration, cinematic lighting, art by artgerm and greg rutkowski\"\n",
    "generate_image(pipe, prompt, steps=100, guidance_scale=13, h=512, w=768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e26c30e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1a6909",
   "metadata": {},
   "source": [
    "## Generate more than one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24764f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(pipe, prompt, negative_prompt=\"\", num_images=5, steps=50, h=512, w=512, guidance_scale=7.5, strength=0.75, seed=custom_generator, save_image=True):\n",
    "\n",
    "    print(prompt)   \n",
    "    \n",
    "    images = pipe(\n",
    "        prompt,\n",
    "        height=h,\n",
    "        width=w,\n",
    "        negative_prompt=negative_prompt,\n",
    "        num_images_per_prompt=num_images,\n",
    "        num_inference_steps=steps,\n",
    "        guidance_scale=guidance_scale,\n",
    "        strength=strength,\n",
    "        generator=seed\n",
    "    ).images\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        display(image)\n",
    "\n",
    "        if save_image==True:\n",
    "            outfilename = 'generated_outputs/' + f'{INFERENCE_SEED}_{i}_' + prompt.replace(' ', '_') + '.png'\n",
    "            image.save(outfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b099291",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"overgrown foliage taking over an abandoned robot body, close - up, biopunk, bokeh, beautiful, lens flare, emotional, sweet, flowers, detailed, picture, trending on artstation, award - winning, shiny, golden\"\n",
    "generate_images(pipe, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fea4a79",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7b93b4",
   "metadata": {},
   "source": [
    "### Generate and save all images together as a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43ea7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid\n",
    "\n",
    "def generate_images_grid(pipe, prompt, negative_prompt=\"\", num_images=5, steps=50, h=512, w=512, guidance_scale=7.5, strength=0.75, seed=custom_generator, save_image=True):\n",
    "    \n",
    "    print(prompt)\n",
    "    \n",
    "    images = pipe(\n",
    "        prompt,\n",
    "        height=h,\n",
    "        width=w,\n",
    "        negative_prompt=negative_prompt,\n",
    "        num_images_per_prompt=num_images,\n",
    "        num_inference_steps=steps,\n",
    "        guidance_scale=guidance_scale,\n",
    "        strength=strength,\n",
    "        generator=seed\n",
    "    ).images\n",
    "\n",
    "    grid = image_grid(images, rows=len(images), cols=1)\n",
    "\n",
    "    if save_image==True:\n",
    "        outfilename = 'generated_outputs/' + f'{INFERENCE_SEED}_grid_' + prompt.replace(' ', '_') + '.png'\n",
    "        grid.save(outfilename)    \n",
    "        \n",
    "    display(grid)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd1aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"overgrown foliage taking over an abandoned robot body, close - up, biopunk, bokeh, beautiful, lens flare, emotional, sweet, flowers, detailed, picture, trending on artstation, award - winning, shiny, golden\"\n",
    "generate_images_grid(pipe, prompt, steps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30f475c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd953aa6",
   "metadata": {},
   "source": [
    "# Image-to-Image text guided generation\n",
    "https://huggingface.co/docs/diffusers/en/using-diffusers/img2img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d031e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# let's download an initial image\n",
    "url = \"https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg\"\n",
    "\n",
    "response = requests.get(url)\n",
    "init_image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "init_image = init_image.resize((768, 512))\n",
    "\n",
    "prompt = \"A fantasy landscape\"\n",
    "\n",
    "image = pipe(prompt=prompt, init_image=init_image, strength=0.75, guidance_scale=7.5, num_inference_steps=100, height=512, width=768)[\"images\"][0]\n",
    "\n",
    "# Print and show results:\n",
    "print(\"\")\n",
    "print(\"This is the original image:\")\n",
    "display(init_image)\n",
    "print(\"\")\n",
    "print(f'The textual prompt is: \"\"{prompt}\"\"')\n",
    "print(\"\")\n",
    "print(\"And this is the generated image:\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293f3d81",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6eb307",
   "metadata": {},
   "source": [
    "## Text-to-Video Generation with AnimateDiff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41521a23",
   "metadata": {},
   "source": [
    "Did you know that you can also generate video or GIFs with Stable Diffusion?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4486dbea",
   "metadata": {},
   "source": [
    "`Experiment (optional)`: Find out how to generate your own GIFs with the diffusers library and AnimateDiff\n",
    "https://huggingface.co/docs/diffusers/en/api/pipelines/animatediff#text-to-video-generation-with-animatediff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d750373",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0364e9020a262cdb7effdb32b8c42f887cf28bfb42db9a25dfdb5db4469544cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
